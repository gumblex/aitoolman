# aitoolman - 可控、透明的LLM应用框架

## 项目介绍
aitoolman 是一个面向开发者的LLM（大语言模型）应用框架，旨在解决现有框架的**供应商锁定、流程不清晰、调试困难**等痛点。框架将AI定位为“工具人”，强调**用户直接控制所有提示词、数据流、控制流**，帮助开发者快速构建稳定、可调试的LLM应用。

## 设计理念
1. **用户完全控制**：所有提示词、数据流、控制流均由用户代码主导，LLM 仅作为执行工具，**无意外操作、无隐藏提示词**
2. **流程透明可调试**：所有发往LLM和从LLM返回的数据均可自定义、可审计，便于排查问题和优化提示词
3. **供应商无关**：通过抽象层统一适配多种LLM提供商，轻松切换模型且充分利用各提供商的特色功能
4. **模块化设计**：组件职责单一，易于测试、替换和复用
5. **生产级特性**：内置资源管理、错误处理、微服务部署、监控审计能力，可直接用于生产环境

| 维度 | aitoolman | 传统 Agent 框架 |
|------|-----------|----------------|
| 定位 | **LLM是工具人，仅执行预设指令** | LLM是智能体，可自主决策 |
| 控制权 | 用户完全控制流程 | 框架隐含控制流 |
| 提示词 | 开发者编写所有提示词，完全自定义 | 自带大量默认提示词，适配非英语场景成本高 |
| 多模型适配 | 原生支持多厂商、多模型，切换成本低 | 多为单一平台优化，适配成本高 |
| 功能边界 | 专注LLM功能编排，无冗余依赖 | 内置向量索引、RAG等大量功能，依赖库臃肿 |
| 适用场景 | 企业级可控流程编排、批量任务处理 | 开放式自主智能体、探索性应用 |

## 核心功能
- **提示词模板化**：将提示词封装为可复用的 Jinja2 模板，集中管理，避免散落各处。
- **灵活的工作流编排**：支持串行、并行及动态 DAG（有向无环图）工作流，轻松处理复杂多步骤任务。
- **原生工具调用支持**：将工具调用作为流程控制机制，实现意图识别或经典函数调用模式。
- **实时流式传输**：通过 `Channel` 系统实现响应内容、推理过程的实时输出，提升交互体验。
- **微服务架构**：可将 LLM 调度器部署为独立服务，实现统一的资源管理、密钥隔离与全局审计。

## 适用场景
aitoolman 适用于多种需要可控、可靠 LLM 集成的场景：

- **专业文本处理**：总结、翻译、数据标注、结构化信息提取。
- **报告内容生成**：基于结构化数据生成标准化的文字报告。
- **可控多轮对话**：通过预设流程处理复杂用户请求，确保交互完全符合业务规则。
- **智能任务编排**：分解复杂业务任务为可执行步骤，根据结果动态调整流程分支。
- **批量任务处理**：高效并行处理大量标准化任务，如工单分类、内容审核、数据清洗。

## 架构概览
1. 用户应用层：业务逻辑实现
2. 应用层 (LLMApplication / LLMWorkflow)：模板管理、流程编排、结果处理
3. 传输层 (LLMClient / Channel)：请求发送、流式响应传输、微服务通信
4. 数据接口层 (ProviderManager)：多厂商适配、请求调度、限流重试
5. LLM 提供商 API (OpenAI / Anthropic 等)：底层LLM服务

## 快速开始
1. `pip install aitoolman`
2. 参考《[开发者文档](quick_start.md)》查看详细框架文档、API说明和示例代码
3. 配置LLM提供商API密钥和模型参数 (llm_config.toml)
4. 编写提示词模板配置 (app_prompt.toml)
5. 通过 LLMApplication 或 LLMWorkflow 构建应用逻辑
